{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ionosphere Data  Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx0f26FcSb7m"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uiff0KsYSq--"
      },
      "source": [
        "iso = pd.read_csv(\"/content/drive/MyDrive/ionosphere_data.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h65nsQwS-sG",
        "outputId": "7c779fb4-2b0f-48c1-c417-a2b0ce580568"
      },
      "source": [
        "iso.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCI4sTIzTESc",
        "outputId": "3b52ddb3-780c-4392-f26a-9c16ad5e343f"
      },
      "source": [
        "iso.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature1     0\n",
              "feature2     0\n",
              "feature3     0\n",
              "feature4     0\n",
              "feature5     0\n",
              "feature6     0\n",
              "feature7     0\n",
              "feature8     0\n",
              "feature9     0\n",
              "feature10    0\n",
              "feature11    0\n",
              "feature12    0\n",
              "feature13    0\n",
              "feature14    0\n",
              "feature15    0\n",
              "feature16    0\n",
              "feature17    0\n",
              "feature18    0\n",
              "feature19    0\n",
              "feature20    0\n",
              "feature21    0\n",
              "feature22    0\n",
              "feature23    0\n",
              "feature24    0\n",
              "feature25    0\n",
              "feature26    0\n",
              "feature27    0\n",
              "feature28    0\n",
              "feature29    0\n",
              "feature30    0\n",
              "feature31    0\n",
              "feature32    0\n",
              "feature33    0\n",
              "feature34    0\n",
              "label        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P56q9i9aTH80"
      },
      "source": [
        "X = iso.values[1:,0:34].astype(float)\n",
        "Y = iso.values[1:,34]\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y = encoder.transform(Y)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZi9SKPFTU7z"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(34, input_dim=34 , activation= 'relu' ))\n",
        "model.add(Dense(16, activation =\"relu\"))\n",
        "model.add(Dense(1, activation= 'sigmoid' ))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzvHiwjHUMby"
      },
      "source": [
        "model.compile(loss= 'binary_crossentropy' , optimizer=\"Adam\", metrics=[ 'accuracy' ])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTTPWwSyUPFN",
        "outputId": "e0b0feca-7d08-49cd-f8a4-0e7fb1fdc81e"
      },
      "source": [
        "model.fit(X, Y, validation_split=0.4, epochs=100, batch_size=8, verbose=2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "27/27 - 1s - loss: 0.7221 - accuracy: 0.5286 - val_loss: 0.5415 - val_accuracy: 0.8643\n",
            "Epoch 2/100\n",
            "27/27 - 0s - loss: 0.6146 - accuracy: 0.6429 - val_loss: 0.5189 - val_accuracy: 0.8714\n",
            "Epoch 3/100\n",
            "27/27 - 0s - loss: 0.5515 - accuracy: 0.7905 - val_loss: 0.4839 - val_accuracy: 0.9143\n",
            "Epoch 4/100\n",
            "27/27 - 0s - loss: 0.4968 - accuracy: 0.8667 - val_loss: 0.4649 - val_accuracy: 0.9214\n",
            "Epoch 5/100\n",
            "27/27 - 0s - loss: 0.4467 - accuracy: 0.8714 - val_loss: 0.4327 - val_accuracy: 0.9357\n",
            "Epoch 6/100\n",
            "27/27 - 0s - loss: 0.3947 - accuracy: 0.8857 - val_loss: 0.3825 - val_accuracy: 0.9357\n",
            "Epoch 7/100\n",
            "27/27 - 0s - loss: 0.3516 - accuracy: 0.9048 - val_loss: 0.3574 - val_accuracy: 0.9429\n",
            "Epoch 8/100\n",
            "27/27 - 0s - loss: 0.3116 - accuracy: 0.9095 - val_loss: 0.3104 - val_accuracy: 0.9429\n",
            "Epoch 9/100\n",
            "27/27 - 0s - loss: 0.2766 - accuracy: 0.9286 - val_loss: 0.2819 - val_accuracy: 0.9500\n",
            "Epoch 10/100\n",
            "27/27 - 0s - loss: 0.2437 - accuracy: 0.9238 - val_loss: 0.2525 - val_accuracy: 0.9500\n",
            "Epoch 11/100\n",
            "27/27 - 0s - loss: 0.2173 - accuracy: 0.9286 - val_loss: 0.2312 - val_accuracy: 0.9643\n",
            "Epoch 12/100\n",
            "27/27 - 0s - loss: 0.1965 - accuracy: 0.9429 - val_loss: 0.1991 - val_accuracy: 0.9500\n",
            "Epoch 13/100\n",
            "27/27 - 0s - loss: 0.1778 - accuracy: 0.9524 - val_loss: 0.1803 - val_accuracy: 0.9500\n",
            "Epoch 14/100\n",
            "27/27 - 0s - loss: 0.1618 - accuracy: 0.9524 - val_loss: 0.1673 - val_accuracy: 0.9500\n",
            "Epoch 15/100\n",
            "27/27 - 0s - loss: 0.1485 - accuracy: 0.9619 - val_loss: 0.1691 - val_accuracy: 0.9643\n",
            "Epoch 16/100\n",
            "27/27 - 0s - loss: 0.1362 - accuracy: 0.9667 - val_loss: 0.1493 - val_accuracy: 0.9643\n",
            "Epoch 17/100\n",
            "27/27 - 0s - loss: 0.1277 - accuracy: 0.9667 - val_loss: 0.1422 - val_accuracy: 0.9643\n",
            "Epoch 18/100\n",
            "27/27 - 0s - loss: 0.1212 - accuracy: 0.9714 - val_loss: 0.1451 - val_accuracy: 0.9643\n",
            "Epoch 19/100\n",
            "27/27 - 0s - loss: 0.1105 - accuracy: 0.9714 - val_loss: 0.1185 - val_accuracy: 0.9714\n",
            "Epoch 20/100\n",
            "27/27 - 0s - loss: 0.1083 - accuracy: 0.9667 - val_loss: 0.1326 - val_accuracy: 0.9643\n",
            "Epoch 21/100\n",
            "27/27 - 0s - loss: 0.1003 - accuracy: 0.9714 - val_loss: 0.1118 - val_accuracy: 0.9714\n",
            "Epoch 22/100\n",
            "27/27 - 0s - loss: 0.0945 - accuracy: 0.9714 - val_loss: 0.1165 - val_accuracy: 0.9714\n",
            "Epoch 23/100\n",
            "27/27 - 0s - loss: 0.0887 - accuracy: 0.9810 - val_loss: 0.0990 - val_accuracy: 0.9714\n",
            "Epoch 24/100\n",
            "27/27 - 0s - loss: 0.0850 - accuracy: 0.9810 - val_loss: 0.1010 - val_accuracy: 0.9714\n",
            "Epoch 25/100\n",
            "27/27 - 0s - loss: 0.0815 - accuracy: 0.9810 - val_loss: 0.0980 - val_accuracy: 0.9714\n",
            "Epoch 26/100\n",
            "27/27 - 0s - loss: 0.0785 - accuracy: 0.9810 - val_loss: 0.0923 - val_accuracy: 0.9714\n",
            "Epoch 27/100\n",
            "27/27 - 0s - loss: 0.0782 - accuracy: 0.9810 - val_loss: 0.0993 - val_accuracy: 0.9714\n",
            "Epoch 28/100\n",
            "27/27 - 0s - loss: 0.0746 - accuracy: 0.9810 - val_loss: 0.0874 - val_accuracy: 0.9643\n",
            "Epoch 29/100\n",
            "27/27 - 0s - loss: 0.0721 - accuracy: 0.9810 - val_loss: 0.0900 - val_accuracy: 0.9714\n",
            "Epoch 30/100\n",
            "27/27 - 0s - loss: 0.0670 - accuracy: 0.9810 - val_loss: 0.0923 - val_accuracy: 0.9714\n",
            "Epoch 31/100\n",
            "27/27 - 0s - loss: 0.0658 - accuracy: 0.9810 - val_loss: 0.0861 - val_accuracy: 0.9714\n",
            "Epoch 32/100\n",
            "27/27 - 0s - loss: 0.0632 - accuracy: 0.9810 - val_loss: 0.0938 - val_accuracy: 0.9714\n",
            "Epoch 33/100\n",
            "27/27 - 0s - loss: 0.0636 - accuracy: 0.9810 - val_loss: 0.0922 - val_accuracy: 0.9714\n",
            "Epoch 34/100\n",
            "27/27 - 0s - loss: 0.0578 - accuracy: 0.9810 - val_loss: 0.0841 - val_accuracy: 0.9714\n",
            "Epoch 35/100\n",
            "27/27 - 0s - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.0859 - val_accuracy: 0.9714\n",
            "Epoch 36/100\n",
            "27/27 - 0s - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0824 - val_accuracy: 0.9714\n",
            "Epoch 37/100\n",
            "27/27 - 0s - loss: 0.0556 - accuracy: 0.9810 - val_loss: 0.0837 - val_accuracy: 0.9714\n",
            "Epoch 38/100\n",
            "27/27 - 0s - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0856 - val_accuracy: 0.9714\n",
            "Epoch 39/100\n",
            "27/27 - 0s - loss: 0.0488 - accuracy: 0.9905 - val_loss: 0.0795 - val_accuracy: 0.9714\n",
            "Epoch 40/100\n",
            "27/27 - 0s - loss: 0.0486 - accuracy: 0.9905 - val_loss: 0.0793 - val_accuracy: 0.9714\n",
            "Epoch 41/100\n",
            "27/27 - 0s - loss: 0.0486 - accuracy: 0.9810 - val_loss: 0.0835 - val_accuracy: 0.9714\n",
            "Epoch 42/100\n",
            "27/27 - 0s - loss: 0.0446 - accuracy: 0.9905 - val_loss: 0.0766 - val_accuracy: 0.9714\n",
            "Epoch 43/100\n",
            "27/27 - 0s - loss: 0.0445 - accuracy: 0.9857 - val_loss: 0.0812 - val_accuracy: 0.9714\n",
            "Epoch 44/100\n",
            "27/27 - 0s - loss: 0.0456 - accuracy: 0.9857 - val_loss: 0.0845 - val_accuracy: 0.9714\n",
            "Epoch 45/100\n",
            "27/27 - 0s - loss: 0.0433 - accuracy: 0.9905 - val_loss: 0.0753 - val_accuracy: 0.9714\n",
            "Epoch 46/100\n",
            "27/27 - 0s - loss: 0.0428 - accuracy: 0.9952 - val_loss: 0.0775 - val_accuracy: 0.9714\n",
            "Epoch 47/100\n",
            "27/27 - 0s - loss: 0.0409 - accuracy: 0.9905 - val_loss: 0.0767 - val_accuracy: 0.9714\n",
            "Epoch 48/100\n",
            "27/27 - 0s - loss: 0.0395 - accuracy: 0.9905 - val_loss: 0.0737 - val_accuracy: 0.9714\n",
            "Epoch 49/100\n",
            "27/27 - 0s - loss: 0.0366 - accuracy: 0.9952 - val_loss: 0.0767 - val_accuracy: 0.9714\n",
            "Epoch 50/100\n",
            "27/27 - 0s - loss: 0.0363 - accuracy: 0.9905 - val_loss: 0.0776 - val_accuracy: 0.9714\n",
            "Epoch 51/100\n",
            "27/27 - 0s - loss: 0.0353 - accuracy: 0.9905 - val_loss: 0.0826 - val_accuracy: 0.9714\n",
            "Epoch 52/100\n",
            "27/27 - 0s - loss: 0.0356 - accuracy: 0.9952 - val_loss: 0.0781 - val_accuracy: 0.9714\n",
            "Epoch 53/100\n",
            "27/27 - 0s - loss: 0.0343 - accuracy: 0.9952 - val_loss: 0.0780 - val_accuracy: 0.9714\n",
            "Epoch 54/100\n",
            "27/27 - 0s - loss: 0.0345 - accuracy: 0.9952 - val_loss: 0.0767 - val_accuracy: 0.9643\n",
            "Epoch 55/100\n",
            "27/27 - 0s - loss: 0.0342 - accuracy: 0.9952 - val_loss: 0.0741 - val_accuracy: 0.9714\n",
            "Epoch 56/100\n",
            "27/27 - 0s - loss: 0.0311 - accuracy: 0.9952 - val_loss: 0.0779 - val_accuracy: 0.9714\n",
            "Epoch 57/100\n",
            "27/27 - 0s - loss: 0.0406 - accuracy: 0.9905 - val_loss: 0.0802 - val_accuracy: 0.9714\n",
            "Epoch 58/100\n",
            "27/27 - 0s - loss: 0.0302 - accuracy: 0.9952 - val_loss: 0.0807 - val_accuracy: 0.9714\n",
            "Epoch 59/100\n",
            "27/27 - 0s - loss: 0.0292 - accuracy: 0.9952 - val_loss: 0.0794 - val_accuracy: 0.9714\n",
            "Epoch 60/100\n",
            "27/27 - 0s - loss: 0.0280 - accuracy: 0.9952 - val_loss: 0.0817 - val_accuracy: 0.9714\n",
            "Epoch 61/100\n",
            "27/27 - 0s - loss: 0.0269 - accuracy: 0.9952 - val_loss: 0.0805 - val_accuracy: 0.9714\n",
            "Epoch 62/100\n",
            "27/27 - 0s - loss: 0.0278 - accuracy: 0.9952 - val_loss: 0.0792 - val_accuracy: 0.9714\n",
            "Epoch 63/100\n",
            "27/27 - 0s - loss: 0.0261 - accuracy: 0.9952 - val_loss: 0.0796 - val_accuracy: 0.9714\n",
            "Epoch 64/100\n",
            "27/27 - 0s - loss: 0.0263 - accuracy: 0.9952 - val_loss: 0.0819 - val_accuracy: 0.9714\n",
            "Epoch 65/100\n",
            "27/27 - 0s - loss: 0.0260 - accuracy: 0.9952 - val_loss: 0.0798 - val_accuracy: 0.9714\n",
            "Epoch 66/100\n",
            "27/27 - 0s - loss: 0.0248 - accuracy: 0.9952 - val_loss: 0.0817 - val_accuracy: 0.9714\n",
            "Epoch 67/100\n",
            "27/27 - 0s - loss: 0.0240 - accuracy: 0.9952 - val_loss: 0.0832 - val_accuracy: 0.9714\n",
            "Epoch 68/100\n",
            "27/27 - 0s - loss: 0.0244 - accuracy: 0.9952 - val_loss: 0.0825 - val_accuracy: 0.9714\n",
            "Epoch 69/100\n",
            "27/27 - 0s - loss: 0.0254 - accuracy: 0.9952 - val_loss: 0.0838 - val_accuracy: 0.9643\n",
            "Epoch 70/100\n",
            "27/27 - 0s - loss: 0.0253 - accuracy: 0.9952 - val_loss: 0.0797 - val_accuracy: 0.9714\n",
            "Epoch 71/100\n",
            "27/27 - 0s - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.0863 - val_accuracy: 0.9714\n",
            "Epoch 72/100\n",
            "27/27 - 0s - loss: 0.0220 - accuracy: 0.9952 - val_loss: 0.0868 - val_accuracy: 0.9714\n",
            "Epoch 73/100\n",
            "27/27 - 0s - loss: 0.0213 - accuracy: 0.9952 - val_loss: 0.0869 - val_accuracy: 0.9643\n",
            "Epoch 74/100\n",
            "27/27 - 0s - loss: 0.0224 - accuracy: 0.9952 - val_loss: 0.0879 - val_accuracy: 0.9643\n",
            "Epoch 75/100\n",
            "27/27 - 0s - loss: 0.0226 - accuracy: 0.9952 - val_loss: 0.0892 - val_accuracy: 0.9714\n",
            "Epoch 76/100\n",
            "27/27 - 0s - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.0894 - val_accuracy: 0.9714\n",
            "Epoch 77/100\n",
            "27/27 - 0s - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.0897 - val_accuracy: 0.9714\n",
            "Epoch 78/100\n",
            "27/27 - 0s - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.0917 - val_accuracy: 0.9714\n",
            "Epoch 79/100\n",
            "27/27 - 0s - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.0943 - val_accuracy: 0.9714\n",
            "Epoch 80/100\n",
            "27/27 - 0s - loss: 0.0197 - accuracy: 0.9952 - val_loss: 0.0922 - val_accuracy: 0.9643\n",
            "Epoch 81/100\n",
            "27/27 - 0s - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.0964 - val_accuracy: 0.9714\n",
            "Epoch 82/100\n",
            "27/27 - 0s - loss: 0.0184 - accuracy: 0.9952 - val_loss: 0.0951 - val_accuracy: 0.9643\n",
            "Epoch 83/100\n",
            "27/27 - 0s - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.0969 - val_accuracy: 0.9714\n",
            "Epoch 84/100\n",
            "27/27 - 0s - loss: 0.0174 - accuracy: 0.9952 - val_loss: 0.0998 - val_accuracy: 0.9714\n",
            "Epoch 85/100\n",
            "27/27 - 0s - loss: 0.0185 - accuracy: 0.9952 - val_loss: 0.0966 - val_accuracy: 0.9643\n",
            "Epoch 86/100\n",
            "27/27 - 0s - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.1008 - val_accuracy: 0.9643\n",
            "Epoch 87/100\n",
            "27/27 - 0s - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.1039 - val_accuracy: 0.9714\n",
            "Epoch 88/100\n",
            "27/27 - 0s - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.1023 - val_accuracy: 0.9643\n",
            "Epoch 89/100\n",
            "27/27 - 0s - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.1055 - val_accuracy: 0.9643\n",
            "Epoch 90/100\n",
            "27/27 - 0s - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1058 - val_accuracy: 0.9643\n",
            "Epoch 91/100\n",
            "27/27 - 0s - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.1057 - val_accuracy: 0.9643\n",
            "Epoch 92/100\n",
            "27/27 - 0s - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.1068 - val_accuracy: 0.9643\n",
            "Epoch 93/100\n",
            "27/27 - 0s - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.1069 - val_accuracy: 0.9643\n",
            "Epoch 94/100\n",
            "27/27 - 0s - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.1086 - val_accuracy: 0.9643\n",
            "Epoch 95/100\n",
            "27/27 - 0s - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.1120 - val_accuracy: 0.9643\n",
            "Epoch 96/100\n",
            "27/27 - 0s - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.1109 - val_accuracy: 0.9643\n",
            "Epoch 97/100\n",
            "27/27 - 0s - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.1159 - val_accuracy: 0.9571\n",
            "Epoch 98/100\n",
            "27/27 - 0s - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.1152 - val_accuracy: 0.9643\n",
            "Epoch 99/100\n",
            "27/27 - 0s - loss: 0.0130 - accuracy: 0.9952 - val_loss: 0.1175 - val_accuracy: 0.9500\n",
            "Epoch 100/100\n",
            "27/27 - 0s - loss: 0.0111 - accuracy: 0.9952 - val_loss: 0.1132 - val_accuracy: 0.9643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d800aac90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1hbVPKkUs3x",
        "outputId": "99639fd2-440f-4bca-8310-7877ca6ab2b5"
      },
      "source": [
        "model.evaluate(X, Y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.052005790174007416, 0.9828571677207947]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-rhj1oDU23B"
      },
      "source": [
        "Y_pred = model.predict(X)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgh2cqpVVWCA"
      },
      "source": [
        "Y_pred = Y_pred.reshape(Y_pred.shape[0])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7sW8ayDVagY",
        "outputId": "943fcdc2-9aad-4e63-97a6-f5831e18746b"
      },
      "source": [
        "Y_pred"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.1610849e-03, 9.9980074e-01, 3.6180019e-04, 9.9943262e-01,\n",
              "       1.0083914e-02, 9.9852455e-01, 1.4510751e-04, 9.9616504e-01,\n",
              "       3.9830582e-05, 9.9335384e-01, 8.0847612e-06, 9.9524325e-01,\n",
              "       6.5015554e-03, 9.9996650e-01, 5.6249297e-07, 9.9995357e-01,\n",
              "       1.6995441e-06, 9.9051023e-01, 4.4503005e-11, 9.9560630e-01,\n",
              "       1.5129627e-12, 9.9964452e-01, 1.3988348e-12, 9.9657786e-01,\n",
              "       6.3247309e-05, 9.9989665e-01, 1.6077254e-07, 9.9995303e-01,\n",
              "       1.7402408e-08, 9.9504155e-01, 2.2768781e-08, 9.9495906e-01,\n",
              "       2.2524893e-03, 9.9223125e-01, 6.9974551e-05, 9.9879056e-01,\n",
              "       3.9444250e-11, 9.9992615e-01, 4.8732758e-04, 9.9970526e-01,\n",
              "       8.2474622e-07, 9.9869156e-01, 2.8371811e-04, 9.9577200e-01,\n",
              "       1.7381608e-03, 9.9778390e-01, 6.2433895e-07, 9.9931771e-01,\n",
              "       3.0504888e-10, 9.9856937e-01, 1.4334829e-12, 1.0000000e+00,\n",
              "       1.7789907e-11, 9.9854755e-01, 4.9501736e-11, 9.8578531e-01,\n",
              "       1.6653595e-10, 9.9993938e-01, 1.9295852e-07, 9.9995375e-01,\n",
              "       2.1811228e-09, 9.9987662e-01, 2.4187267e-03, 9.9145889e-01,\n",
              "       1.5664786e-02, 9.9976385e-01, 3.2058362e-10, 9.9999940e-01,\n",
              "       4.3326616e-04, 9.9997962e-01, 8.8125562e-16, 9.9978185e-01,\n",
              "       3.7890673e-04, 9.9994624e-01, 9.4878466e-11, 9.9995458e-01,\n",
              "       2.0850424e-05, 9.9999118e-01, 6.7491493e-07, 9.8981887e-01,\n",
              "       2.0751357e-04, 9.9936581e-01, 4.3844730e-02, 9.9962431e-01,\n",
              "       4.4974595e-02, 9.9913394e-01, 1.1121929e-03, 9.6623468e-01,\n",
              "       8.9896023e-03, 9.9802947e-01, 2.9113256e-09, 9.8332793e-01,\n",
              "       7.0780516e-04, 9.9830413e-01, 6.1775446e-03, 9.9961716e-01,\n",
              "       9.9994755e-01, 1.6033649e-04, 9.9975300e-01, 2.1809340e-03,\n",
              "       9.9964464e-01, 4.2757556e-06, 9.9992812e-01, 3.0893087e-04,\n",
              "       9.9991274e-01, 7.7355105e-07, 9.9942720e-01, 9.3240687e-06,\n",
              "       9.9922574e-01, 9.5475771e-06, 9.9986959e-01, 3.5983324e-04,\n",
              "       9.9998462e-01, 2.1548271e-03, 9.5597649e-01, 6.4779997e-02,\n",
              "       9.9984348e-01, 6.6506818e-09, 9.9971819e-01, 4.8723817e-04,\n",
              "       9.9826956e-01, 2.5917782e-07, 9.6721530e-01, 1.8567516e-10,\n",
              "       9.9919713e-01, 3.7306547e-04, 9.9959457e-01, 5.7265139e-09,\n",
              "       9.9976897e-01, 1.9225180e-03, 9.8896527e-01, 3.6306887e-05,\n",
              "       9.8215139e-01, 1.8544451e-07, 9.9998569e-01, 8.9936614e-11,\n",
              "       9.3873417e-01, 1.4525652e-04, 9.8860884e-01, 4.7875270e-10,\n",
              "       9.9981678e-01, 9.3083978e-03, 8.7447894e-01, 7.4434102e-01,\n",
              "       9.9185359e-01, 9.8283072e-06, 9.9991608e-01, 4.6027899e-03,\n",
              "       9.9984854e-01, 1.3489240e-05, 9.9772561e-01, 1.1267126e-02,\n",
              "       9.9999571e-01, 1.2605846e-02, 9.9921751e-01, 1.9033551e-02,\n",
              "       9.9908590e-01, 3.7458092e-02, 9.9997139e-01, 2.8628856e-02,\n",
              "       9.9903822e-01, 4.8530695e-14, 9.9998271e-01, 5.2309036e-04,\n",
              "       9.9999738e-01, 4.3340373e-11, 9.9981368e-01, 1.2740687e-05,\n",
              "       9.9672616e-01, 1.1927040e-13, 9.9680817e-01, 5.7290981e-07,\n",
              "       9.9979508e-01, 3.0100346e-03, 9.9883020e-01, 1.5333295e-04,\n",
              "       9.9830347e-01, 3.5499752e-02, 9.9234575e-01, 9.0018348e-10,\n",
              "       9.9484909e-01, 1.2764984e-13, 9.9318004e-01, 5.2415334e-08,\n",
              "       9.9999487e-01, 4.8512551e-18, 9.9999905e-01, 8.7346803e-11,\n",
              "       9.9546456e-01, 2.4529303e-08, 9.6877640e-01, 8.3590858e-06,\n",
              "       9.9974465e-01, 8.9170997e-12, 9.9965048e-01, 1.6506339e-08,\n",
              "       9.9976075e-01, 1.5638676e-07, 9.9922282e-01, 1.0134587e-07,\n",
              "       9.9368644e-01, 2.0930171e-04, 9.9991071e-01, 1.9246340e-04,\n",
              "       9.9936742e-01, 1.9248378e-07, 9.8110151e-01, 2.2650659e-03,\n",
              "       9.9960220e-01, 1.5442952e-13, 9.9495876e-01, 2.1907415e-07,\n",
              "       8.2768631e-01, 4.0507317e-04, 9.9999571e-01, 9.9133164e-01,\n",
              "       9.9957424e-01, 3.1414412e-08, 9.9793583e-01, 1.1614797e-05,\n",
              "       9.9167061e-01, 4.7879272e-05, 9.9950749e-01, 7.3215365e-04,\n",
              "       9.9475157e-01, 1.6041149e-06, 9.9999595e-01, 1.5822053e-04,\n",
              "       9.9844170e-01, 9.7589118e-06, 9.9991733e-01, 7.6529017e-13,\n",
              "       9.9908984e-01, 7.6688337e-01, 9.9086183e-01, 8.5113835e-01,\n",
              "       9.9824619e-01, 2.0237207e-02, 9.9957323e-01, 4.2490873e-07,\n",
              "       9.9843454e-01, 9.7431672e-01, 9.9733788e-01, 4.0604472e-03,\n",
              "       9.9753976e-01, 5.4178884e-07, 9.9711049e-01, 4.2757556e-06,\n",
              "       9.9998903e-01, 4.6284054e-13, 9.9999654e-01, 5.1056686e-05,\n",
              "       9.9999797e-01, 9.7252494e-01, 9.9999547e-01, 9.9921781e-01,\n",
              "       9.9897134e-01, 9.9676275e-01, 9.9978995e-01, 9.7180128e-01,\n",
              "       9.9533737e-01, 9.9802899e-01, 9.9833924e-01, 9.9678791e-01,\n",
              "       9.9908996e-01, 9.9953508e-01, 9.9730122e-01, 9.9967504e-01,\n",
              "       9.9511683e-01, 9.9984753e-01, 9.5588058e-01, 9.5583618e-01,\n",
              "       9.8449415e-01, 9.9913734e-01, 9.9893856e-01, 9.8751158e-01,\n",
              "       9.3922353e-01, 9.9611789e-01, 9.9887812e-01, 9.9997354e-01,\n",
              "       9.9992400e-01, 9.9997622e-01, 9.9998558e-01, 9.5883834e-01,\n",
              "       9.0915877e-01, 9.9875736e-01, 9.9976563e-01, 9.9415034e-01,\n",
              "       9.9423480e-01, 8.8394839e-01, 9.9765998e-01, 9.9319559e-01,\n",
              "       9.9258041e-01, 6.9769526e-01, 8.9365548e-01, 9.9997640e-01,\n",
              "       9.9997956e-01, 9.9996966e-01, 9.9997795e-01, 9.9998498e-01,\n",
              "       9.9993551e-01, 9.9983513e-01, 9.9971551e-01, 9.9978513e-01,\n",
              "       9.7649312e-01, 9.4026178e-01, 9.9997842e-01, 9.9987972e-01,\n",
              "       9.9997389e-01, 9.9998546e-01, 9.9996543e-01, 9.9940187e-01,\n",
              "       9.6381569e-01, 9.9997234e-01, 9.9999058e-01, 9.9999791e-01,\n",
              "       7.3698997e-01, 9.9965799e-01, 9.9992216e-01, 9.9981707e-01,\n",
              "       9.9980474e-01, 9.9986017e-01, 9.8725003e-01, 9.9999374e-01,\n",
              "       9.9999720e-01, 9.9999875e-01, 9.9935144e-01, 9.9971259e-01,\n",
              "       9.9994028e-01, 9.9993980e-01, 9.9984729e-01, 9.9968863e-01,\n",
              "       9.9994326e-01, 9.9988091e-01, 9.9996316e-01, 9.9999684e-01,\n",
              "       9.9999869e-01, 9.9357486e-01, 9.9997479e-01, 1.1437401e-01,\n",
              "       9.9992132e-01, 9.9704403e-01, 9.8281574e-01, 9.9973238e-01,\n",
              "       8.6580575e-01, 9.9983937e-01, 9.9991012e-01, 9.9991912e-01,\n",
              "       9.9979734e-01, 9.9895096e-01], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}